{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "RANDOM_STATE = 32  # DO NOT CHANGE, images will have to be resorted\n",
    "PROCESSED_IMAGES_DIR = \"data/images_processed/\"\n",
    "PROCESSED_IMAGE_ARRAY_NPY = \"data/image_processed_array.npy\"\n",
    "\n",
    "TRAIN_IMAGES_DIR = \"data/train_images/\"\n",
    "TEST_IMAGES_DIR = \"data/test_images/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data and split for testing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from SQLite database\n",
    "connection = sqlite3.connect(\"data/galaxy_data.sqlite\")\n",
    "df_import = pd.read_sql(\"SELECT * from galaxy_data\", connection)\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure there are no null values in data\n",
    "df_import.isnull().any(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239267, 37)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only needed values\n",
    "stratify_data = df_import[\"class_reduced\"].values\n",
    "x_image_id_names = df_import[\"asset_id\"]\n",
    "\n",
    "y_output_data = df_import.drop([\"objid\", \"sample\", \"asset_id\", \"dr7objid\", \"ra\", \"dec\", \"gz2_class\", \"class_reduced\"], axis=1)\n",
    "y_output_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RANDOM_STATE` needs to be the same as the value in `data_image_cleaning.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into testing and training\n",
    "# X is asset names, not the actual images\n",
    "X_train_assets, X_test_assets, y_train, y_test = train_test_split(x_image_id_names,\n",
    "                                                                  y_output_data,\n",
    "                                                                  random_state=RANDOM_STATE,\n",
    "                                                                  stratify=stratify_data)\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_png_images_from_directory(directory: str,  image_list: list[int]) -> np.array:\n",
    "    \"\"\"\n",
    "    Load grayscale PNG images from a directory into a numpy array.\n",
    "\n",
    "    Images must be integer names in `image_list`, order is important\n",
    "    \n",
    "    :param directory: path to directory\n",
    "    :param image_list: array of integers representing file names\n",
    "    :return: array of image arrays\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    for img_name in image_list:\n",
    "        img_array = cv2.imread(f\"{directory}{img_name}.png\", cv2.IMREAD_GRAYSCALE).astype(\"float32\") / 255.0\n",
    "        images.append(img_array)\n",
    "    X_image_array = np.array(images)\n",
    "    return X_image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_images Shape: (59817, 106, 106)\n",
      "X_train_images Size 2688415248 bytes\n",
      "y_train Shape: (179450, 37)\n"
     ]
    }
   ],
   "source": [
    "# TODO THIS IS TEST_IMAGES FOR SPEED\n",
    "# X_train_images = load_png_images_from_directory(TRAIN_IMAGES_DIR, X_train_assets)  # Actual values\n",
    "X_train_images = load_png_images_from_directory(TEST_IMAGES_DIR, X_test_assets)  # TODO test values taking its place\n",
    "print(\"X_train_images Shape:\", X_train_images.shape)\n",
    "print(\"X_train_images Size\", X_train_images.nbytes, \"bytes\")\n",
    "print(\"y_train Shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test Shape: (59817, 37)\n"
     ]
    }
   ],
   "source": [
    "print(\"y_test Shape:\", y_test.shape)  # TODO move to end next to X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create weights with sklearn\n",
    "# # https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html\n",
    "# class_weights = compute_class_weight('balanced', np.unique(y_train), y_train)  # unique does not make sense for a regression problem\n",
    "\n",
    "# class_weights = np.sum(y_train, axis=0) / np.sum(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Model\n",
    "This model is a regression model even though is appears to be classifying galaxies. That is because it is really measuring the confidence levels of the group of people classifying the galaxies.\n",
    "\n",
    "- Convolution Layers\n",
    "- Pooling\n",
    "- Dropout\n",
    "- Dense Layers\n",
    "- 37 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 104, 104, 16)      160       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 52, 52, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 50, 50, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 25, 25, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 23, 23, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 11, 11, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 7744)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               991360    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 37)                2405      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,025,317\n",
      "Trainable params: 1,025,317\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = X_train_images[0].shape[0]\n",
    "INPUT_SHAPE = (IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "# Create a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolution layers\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=INPUT_SHAPE))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten the output from convolution layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add dense layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2, seed=RANDOM_STATE))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Add the output layer with 37 units (for 37 classes)\n",
    "# TODO is `softmax` good for regression, probably relu?\n",
    "# model.add(Dense(37, activation='softmax'))\n",
    "model.add(Dense(37, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "# TODO Since values are like confidence levels from the classifiers, this is really a regression, not a classification\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[\"mse\"])  # mse=mean_squared_error\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create weight function/array/list to give weight to rare categories\n",
    "class_weights = {\n",
    "    0: 1,   # t01_smooth\n",
    "    1: 1,   # t01_features\n",
    "    2: 1,   # t01_star_artifact\n",
    "    3: 1,   # t02_edge_on_yes\n",
    "    4: 1,   # t02_edge_on_no\n",
    "    5: 1,   # t03_bar_yes\n",
    "    6: 1,   # t03_bar_no\n",
    "    7: 1,   # t04_spiral_yes\n",
    "    8: 1,   # t04_spiral_no\n",
    "    9: 1,   # t05_bulge_prominence_no_bulge\n",
    "    10: 1,  # t05_bulge_prominence_just\n",
    "    11: 1,  # t05_bulge_prominence_obvious\n",
    "    12: 1,  # t05_bulge_prominence_dominant\n",
    "    13: 1,  # t06_odd_yes\n",
    "    14: 1,  # t06_odd_no\n",
    "    15: 1,  # t07_rounded_completely_round\n",
    "    16: 1,  # t07_rounded_in_between\n",
    "    17: 1,  # t07_rounded_cigar_shaped\n",
    "    18: 1,  # t08_odd_feature_ring\n",
    "    19: 1,  # t08_odd_feature_lens_or_arc\n",
    "    20: 1,  # t08_odd_feature_disturbed\n",
    "    21: 1,  # t08_odd_feature_irregular\n",
    "    22: 1,  # t08_odd_feature_other\n",
    "    23: 1,  # t08_odd_feature_merger\n",
    "    24: 1,  # t08_odd_feature_dust_lane\n",
    "    25: 1,  # t09_bulge_shape_rounded\n",
    "    26: 1,  # t09_bulge_shape_boxy\n",
    "    27: 1,  # t09_bulge_shape_no_bulge\n",
    "    28: 1,  # t10_arms_winding_tight\n",
    "    29: 1,  # t10_arms_winding_medium\n",
    "    30: 1,  # t10_arms_winding_loose\n",
    "    31: 1,  # t11_arms_number_1\n",
    "    32: 1,  # t11_arms_number_2\n",
    "    33: 1,  # t11_arms_number_3\n",
    "    34: 1,  # t11_arms_number_4\n",
    "    35: 1,  # t11_arms_number_more_than_4\n",
    "    36: 1,  # t11_arms_number_cant_tell\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add callbacks for Early Stopping and Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "# https://www.tensorflow.org/tutorials/keras/save_and_load\n",
    "checkpoints = ModelCheckpoint(\"data/model/checkpoints/cp-{epoch:04d}.ckpt\", monitor=\"mse\", mode=\"min\", verbose=0, save_weights_only=True)\n",
    "early_stopping = EarlyStopping(monitor=\"mse\", patience=5)\n",
    "callbacks_ = [checkpoints, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 54s 1s/step - loss: 0.0830 - mse: 0.0830\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.0780 - mse: 0.0780\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.0741 - mse: 0.0741\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 34s 1s/step - loss: 0.0718 - mse: 0.0718\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 33s 1s/step - loss: 0.0703 - mse: 0.0703\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 33s 1s/step - loss: 0.0691 - mse: 0.0691\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 33s 1s/step - loss: 0.0680 - mse: 0.0680\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 33s 1s/step - loss: 0.0671 - mse: 0.0671\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 35s 1s/step - loss: 0.0658 - mse: 0.0658\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 33s 1s/step - loss: 0.0649 - mse: 0.0649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x299b2735df0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train_images,  # TODO make sure this is correct TESTING ONLY, this is not actually the training data\n",
    "          y_test,  # TODO testing only replace with y_train\n",
    "          # class_weight=class_weights,\n",
    "          epochs=10,\n",
    "          callbacks=callbacks_,\n",
    "          batch_size=2_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"data/model/GalaxyConfidenceModel.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_images = load_png_images_from_directory(TEST_IMAGES_DIR, X_test_assets)\n",
    "print(\"X_test_images Shape:\", X_test_images.shape)\n",
    "print(\"X_test_images Size\", X_test_images.nbytes, \"bytes\")\n",
    "print(\"y_test Shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "# model_loss, model_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "# print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "model_loss, model_metrics = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Metrics: {model_metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "t01_smooth_or_features_a01_smooth_debiased              0.263093\n",
       "t01_smooth_or_features_a02_features_or_disk_debiased    0.665628\n",
       "t01_smooth_or_features_a03_star_or_artifact_debiased    0.031351\n",
       "t02_edgeon_a04_yes_debiased                             0.065646\n",
       "t02_edgeon_a05_no_debiased                              0.916642\n",
       "t03_bar_a06_bar_debiased                                0.296509\n",
       "t03_bar_a07_no_bar_debiased                             0.607082\n",
       "t04_spiral_a08_spiral_debiased                          0.472778\n",
       "t04_spiral_a09_no_spiral_debiased                       0.482960\n",
       "t05_bulge_prominence_a10_no_bulge_debiased              0.038637\n",
       "t05_bulge_prominence_a11_just_noticeable_debiased       0.379940\n",
       "t05_bulge_prominence_a12_obvious_debiased               0.504770\n",
       "t05_bulge_prominence_a13_dominant_debiased              0.115812\n",
       "t06_odd_a14_yes_debiased                                0.623475\n",
       "t06_odd_a15_no_debiased                                 0.380051\n",
       "t07_rounded_a16_completely_round_debiased               0.391151\n",
       "t07_rounded_a17_in_between_debiased                     0.516615\n",
       "t07_rounded_a18_cigar_shaped_debiased                   0.154525\n",
       "t08_odd_feature_a19_ring_debiased                       0.330643\n",
       "t08_odd_feature_a20_lens_or_arc_debiased                0.085557\n",
       "t08_odd_feature_a21_disturbed_debiased                  0.132483\n",
       "t08_odd_feature_a22_irregular_debiased                  0.077400\n",
       "t08_odd_feature_a23_other_debiased                      0.286799\n",
       "t08_odd_feature_a24_merger_debiased                     0.121314\n",
       "t08_odd_feature_a38_dust_lane_debiased                  0.044235\n",
       "t09_bulge_shape_a25_rounded_debiased                    0.400718\n",
       "t09_bulge_shape_a26_boxy_debiased                       0.052809\n",
       "t09_bulge_shape_a27_no_bulge_debiased                   0.115332\n",
       "t10_arms_winding_a28_tight_debiased                     0.177108\n",
       "t10_arms_winding_a29_medium_debiased                    0.261599\n",
       "t10_arms_winding_a30_loose_debiased                     0.080093\n",
       "t11_arms_number_a31_1_debiased                          0.101501\n",
       "t11_arms_number_a32_2_debiased                          0.305549\n",
       "t11_arms_number_a33_3_debiased                          0.108703\n",
       "t11_arms_number_a34_4_debiased                          0.035420\n",
       "t11_arms_number_a36_more_than_4_debiased                0.050021\n",
       "t11_arms_number_a37_cant_tell_debiased                  0.160004\n",
       "dtype: float32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a face on Barred Spiral Galaxy with 2 arms. It has been scaled down and has very distinct features\n",
    "predict_img = cv2.imread(r\"C:\\Users\\Zachary\\Documents\\UTB\\Classwork\\Project4\\examples\\test_spiral_bar_2_arm.png\", cv2.IMREAD_GRAYSCALE).astype(\"float32\") / 255.0\n",
    "predict_img = np.expand_dims(predict_img, axis=0)  # I do not know why these are necessary but they are\n",
    "predict_img = np.expand_dims(predict_img, axis=3)  # ^\n",
    "print(predict_img.shape)\n",
    "predictions = model.predict(predict_img)\n",
    "S_predict = pd.Series(predictions[0], y_output_data.columns.values)\n",
    "S_predict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
