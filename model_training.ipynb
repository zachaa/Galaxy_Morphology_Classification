{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import sqlite3\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "RANDOM_STATE = 32\n",
    "PROCESSED_IMAGES_DIR = \"data/images_processed/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data and split for testing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from SQLite database?\n",
    "connection = sqlite3.connect(\"data/galaxy_data.sqlite\")\n",
    "df_import = pd.read_sql(\"SELECT * from galaxy_data\", connection)\n",
    "connection.close()\n",
    "\n",
    "# keep only needed values\n",
    "stratify_data = df_import[\"class_reduced\"].values.to_list()\n",
    "y_output_data = df_import.drop([\"objid\", \"sample\", \"asset_id\", \"dr7objid\", \"ra\", \"dec\", \"gz2_class\", \"class_reduced\"], axis=1)\n",
    "y_output_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the images to a numpy array\n",
    "image_files = glob.glob(PROCESSED_IMAGES_DIR + \"*.jpg\")\n",
    "\n",
    "images = []\n",
    "for img_path in image_files:\n",
    "    img = Image.open(img_path)\n",
    "    # images should already be the correct size and grayscale\n",
    "\n",
    "    # Convert the image to a NumPy array\n",
    "    img_array = np.array(img)\n",
    "\n",
    "    # Normalize pixel values to the range [0, 1]\n",
    "    img_array = img_array / 255.0\n",
    "\n",
    "    images.append(img_array)\n",
    "\n",
    "X_images_array = np.array(images)\n",
    "X_images_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_images_array,\n",
    "                                                    y_output_data,\n",
    "                                                    random_state=RANDOM_STATE,\n",
    "                                                    stratify=stratify_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Model\n",
    "- Convolution Layers\n",
    "- Pooling\n",
    "- Dropout\n",
    "- Dens Layers\n",
    "- 37 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = X_train[0].shape[0]\n",
    "INPUT_SHAPE = (IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "# Create a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolution layers\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=INPUT_SHAPE))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten the output from convolution layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add dense layers\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2, seed=RANDOM_STATE))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Add the output layer with 37 units (for 37 classes)\n",
    "model.add(Dense(37, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create weight function/array/list to give weight to rare categories\n",
    "class_weights = {\n",
    "    0: 1,   # t01_smooth\n",
    "    1: 1,   # t01_features\n",
    "    2: 1,   # t01_star_artifact\n",
    "    3: 1,   # t02_edge_on_yes\n",
    "    4: 1,   # t02_edge_on_no\n",
    "    5: 1,   # t03_bar_yes\n",
    "    6: 1,   # t03_bar_no\n",
    "    7: 1,   # t04_spiral_yes\n",
    "    8: 1,   # t04_spiral_no\n",
    "    9: 1,   # t05_bulge_prominence_no_bulge\n",
    "    10: 1,  # t05_bulge_prominence_just\n",
    "    11: 1,  # t05_bulge_prominence_obvious\n",
    "    12: 1,  # t05_bulge_prominence_dominant\n",
    "    13: 1,  # t06_odd_yes\n",
    "    14: 1,  # t06_odd_no\n",
    "    15: 1,  # t07_rounded_completely_round\n",
    "    16: 1,  # t07_rounded_in_between\n",
    "    17: 1,  # t07_rounded_cigar_shaped\n",
    "    18: 1,  # t08_odd_feature_ring\n",
    "    19: 1,  # t08_odd_feature_lens_or_arc\n",
    "    20: 1,  # t08_odd_feature_disturbed\n",
    "    21: 1,  # t08_odd_feature_irregular\n",
    "    22: 1,  # t08_odd_feature_other\n",
    "    23: 1,  # t08_odd_feature_merger\n",
    "    24: 1,  # t08_odd_feature_dust_lane\n",
    "    25: 1,  # t09_bulge_shape_rounded\n",
    "    26: 1,  # t09_bulge_shape_boxy\n",
    "    27: 1,  # t09_bulge_shape_no_bulge\n",
    "    28: 1,  # t10_arms_winding_tight\n",
    "    29: 1,  # t10_arms_winding_medium\n",
    "    30: 1,  # t10_arms_winding_loose\n",
    "    31: 1,  # t11_arms_number_1\n",
    "    32: 1,  # t11_arms_number_2\n",
    "    33: 1,  # t11_arms_number_3\n",
    "    34: 1,  # t11_arms_number_4\n",
    "    35: 1,  # t11_arms_number_more_than_4\n",
    "    36: 1,  # t11_arms_number_cant_tell\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          class_weight=class_weights,\n",
    "          epochs=10,\n",
    "          batch_size=1_000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
